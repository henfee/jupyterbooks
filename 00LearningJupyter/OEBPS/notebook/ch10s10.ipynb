{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
   "<html xmlns=\"http://www.w3.org/1999/xhtml\"><head><title>Summary</title><link rel=\"stylesheet\" href=\"epub.css\" type=\"text/css\"/><meta name=\"generator\" content=\"DocBook XSL Stylesheets V1.75.2\"/></head><body id=\"page\"><div class=\"section\" title=\"Summary\"><div class=\"titlepage\"><div><div><h1 class=\"title\"><a id=\"ch10lvl1sec87\"/>Summary</h1></div></div></div><p>In this chapter, we used Spark functionality via Python coding for Jupyter. First, we installed the Spark additions to Jupyter on a Windows machine and a Mac machine. We wrote an initial script that just read lines from a text file. We went further and determined the word counts in that file. We added sorting to the results. There was a script to estimate Pi. We evaluated web log files for anomalies. We determined a set of prime numbers. And we evaluated a text stream for some characteristics.</p></div></body></html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

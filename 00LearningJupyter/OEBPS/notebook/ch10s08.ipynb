{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
   "<html xmlns=\"http://www.w3.org/1999/xhtml\"><head><title>Spark text file analysis</title><link rel=\"stylesheet\" href=\"epub.css\" type=\"text/css\"/><meta name=\"generator\" content=\"DocBook XSL Stylesheets V1.75.2\"/></head><body id=\"page\"><div class=\"section\" title=\"Spark text file analysis\"><div class=\"titlepage\"><div><div><h1 class=\"title\"><a id=\"ch10lvl1sec85\"/>Spark text file analysis</h1></div></div></div><p>In this example, we will look through a news article to determine some basic information from it.</p><p>We will be using the following script against the 2600raid&#xA0;news article (from <a class=\"ulink\" href=\"http://newsitem.com/\">http://newsitem.com/</a>):</p><pre class=\"programlisting\">\n<span class=\"strong\"><strong>import pyspark</strong></span>\n<span class=\"strong\"><strong>if not 'sc' in globals():</strong></span>\n<span class=\"strong\"><strong>    sc = pyspark.SparkContext()</strong></span>\n<span class=\"strong\"><strong>sentences = sc.textFile('2600raid.txt') \\</strong></span>\n<span class=\"strong\"><strong>    .glom() \\</strong></span>\n<span class=\"strong\"><strong>    .map(lambda x: \" \".join(x)) \\</strong></span>\n<span class=\"strong\"><strong>    .flatMap(lambda x: x.split(\".\"))</strong></span>\n<span class=\"strong\"><strong>print(sentences.count(),\"sentences\")</strong></span>\n<span class=\"strong\"><strong>bigrams = sentences.map(lambda x:x.split()) \\</strong></span>\n<span class=\"strong\"><strong>    .flatMap(lambda x: [((x[i],x[i+1]),1) for i in range(0,len(x)-1)])</strong></span>\n<span class=\"strong\"><strong>print(bigrams.count(),\"bigrams\")</strong></span>\n<span class=\"strong\"><strong>frequent_bigrams = bigrams.reduceByKey(lambda x,y:x+y) \\</strong></span>\n<span class=\"strong\"><strong>    .map(lambda x:(x[1],x[0])) \\</strong></span>\n<span class=\"strong\"><strong>    .sortByKey(False)</strong></span>\n<span class=\"strong\"><strong>frequent_bigrams.take(10)</strong></span>\n</pre><p>The code reads in the article and splits up the article into sentences as determined by ending with a period. From there, the code maps out the bigrams present. A bigram is a pair of words that appear next to each other. We then sort the list and print out the top 10 most prevalent pairs.</p><p>When we run this in a notebook, we see these results:</p><p>\n</p><div class=\"mediaobject\"><img src=\"graphics/image_10_007.jpg\" alt=\"Spark text file analysis\"/></div><p>\n</p><p>I really had no idea what to expect from the output. It's curious that you can glean some insights into the article as <code class=\"literal\">'the'</code> and <code class=\"literal\">'mall'</code> appear 15 times and <code class=\"literal\">'the'</code> and <code class=\"literal\">'guards'</code> appear 11 times-a raid must have occurred in a mall and included the security guards in some manner!</p></div></body></html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
